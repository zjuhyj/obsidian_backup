参考：[贝叶斯信息准则（BIC）-CSDN博客](https://blog.csdn.net/u013172930/article/details/144892741)

- 贝叶斯信息准则（Bayesian Information Criterion, BIC），又称 Schwarz信息准则（Schwarz Information Criterion, SIC），是一种用于统计模型选择的准则。
	- 旨在在多个候选模型中选择最优模型，通过权衡模型的**拟合优度**和**复杂度**，以避免过拟合。
	- **BIC值越小，模型越优**
- BIC计算公式为：
	- $$BIC=ln(n)k−2ln(L)$$
		- $n$ ：样本量（数据点数量）
		- $k$ ：模型中自由参数的数量（包括截距项）
		- $L$ ：模型在数据上的**最大似然估计值**（Maximum Likelihood Estimation, MLE）
	-  $ln⁡(n)k$：对模型复杂度的惩罚，参数越多，惩罚越大。
		- 相比于 AIC（赤池信息准则），BIC 的惩罚项依赖于样本量，当n较大时，惩罚更为严格
	- $−2ln(L)$ ：模型的拟合优度，似然值越大（拟合越好），该项值越小。

- **应用步骤**：
	1.  定义候选模型
		- 定义一组候选模型，这些模型可以有不同的参数数量或不同的结构
	2. 估计参数，计算最大似然估计$\widehat{L}$
		1. 拟合模型：对每个模型，使用<u>最大似然估计方法</u>估计参数
		2. 计算最大似然估计值：对于每个模型，似然函数的估计值$\widehat{L}$
	3. 计算BIC值
		- 根据BIC的公式，计算每个模型的BIC值
	4. 选择最优模型：选择BIC值最小的模型作为最佳模型


<br>

- 与其他准则的比较
	- ![[Pasted image 20250311220517.png]]

---

- **最大似然估计**（Maximum Likelihood Estimation，MLE）
	- 一种统计方法，用于在给定数据的情况下，**估计概率模型的参数**。
	- 核心思想：找到一组参数值，使得在这些参数下，观测到的数据出现的概率最大。
- **似然函数**（Likelihood Function）
	- 最大似然估计的基础，它表示在给定参数下观测到数据的<span style="color:red;"><strong>概率</strong></span>。
	- 最大化似然函数：
		- 在给定的观测数据下，找到一组参数值，使得这个参数值下的似然函数取得最大值。换句话说，<u>就是在所有可能的参数值中，选择那个使得观测到的数据最有可能（概率最大）的参数值</u>。

![[Pasted image 20250312130113.png]]
![[Pasted image 20250312130123.png]]